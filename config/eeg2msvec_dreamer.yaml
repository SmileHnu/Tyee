dataset:
  batch_size: 32
  dataset: EEG2RepDREAMERDataset
  eval:
  - car_dev.txt
  - car_test.txt
  num_workers: 2
  path: /home/taoz/data/EEG2Rep
  train: DREAMER.npy
  transforms:
    select:
    - MFCC

lr_scheduler:
  gamma: 0.1
  select: StepLR
  step_size: 20

model:
  downstream:
    classes: 2
    num_feat_dim: 256
    select: EmoMLP
  upstream:
    select: EEG2MSVecExpert
    trainable: false
    # ckpt: /home/taoz/code/p4seq/eeg2msvec/2024-11-01/15-07-13/checkpoints/checkpoint_994_275000.bak.pt
    # ckpt: /home/taoz/code/p4seq/eeg2msvec/2024-11-08/16-15-22/checkpoints/checkpoint_633_175000.pt
    ckpt: /home/taoz/code/p4seq/eeg2msvec/2024-11-08/16-15-22/checkpoints/checkpoint_813_225000.pt
    expert:
      enable: true
      # hooks:
        # module_path: 
        #   - self.expert_model.model.encoder.final_fused_layer
        # transform: "lambda input, output: output"
  
optimizer:
  lr: 0.0001
  select: SGD

task:
  select: DREAMERTask

  loss:
    select: CrossEntropyLoss
    # weight:
    # - 1.0
    # - 1.0
    # - 1.0
    # - 2.0
  

trainer:
  ddp_backend: gloo
  fp16: false
  total_steps: 15000
  save_interval: 20
  eval_interval: 20
  log_interval: 100
  world_size: 1
