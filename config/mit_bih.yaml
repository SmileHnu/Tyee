common:
  seed: 2025
  verbose: true
  exp_dir: experiments

dataset:
  batch_size: 256
  dataset: mit_bih_dataset.MITBIHDataset
  num_workers: 4
  root_path:
    train: '/home/lingyus/data/mit-bih-arrhythmia-database-1.0.0'
    val:
    # test: 
  io_path:
    train: "/home/lingyus/data/mit-bih-arrhythmia-database-1.0.0/processed_wavelet"
    val: 
    test: 
  io_mode: pickle
  split: 
    select: HoldOut
    init_params:
      split_path: /home/lingyus/data/test/mit_bih_split
      val_size: 0.2
      random_state: 42
      shuffle: true
  other:
    pre_offset: 100
    post_offset: 200

  before_trial:
    ecg:
      WaveletTransform:
        wavelet: 'db5'
        level: 9
      # Normalize:
      #   method: zscore_per_channel
  offline_transform:
    ecg:
      PickChannels:
        channels: ['MLII']
      # Normalize:
      #   method: zscore_per_channel

 


lr_scheduler:
  select: TriangularLRScheduler
  # total_epochs: 1000
  # eta_min: 1e-6
  # epoch_size: 1
  # metric: loss
  # patience_epochs: 1
  # warmup_start_lr: 0
  # warmup_epochs: 1
  # hold_epochs: 1
  # decay_epochs: 1
  period_epochs: 1
  t_mult: 2

model:
  select: conformer.Conformer
  n_outputs: 4
  n_chans: 1
  n_times: 300
  att_depth: 3
  att_heads: 4

  # select: ECGCNN

  # select: EcgResNet34
  # num_classes: 4

  # select: EEGNet
  # n_chans: 1
  # chunk_size: 300
  # num_classes: 4
    

optimizer:
  lr:  0.001
  select: Adam
  # weight_decay: 0.05             # 权重衰减 (L2正则化)
  # layer_decay: 0.65                # 层级学习率衰减

task:
  loss:
    select: FocalLoss
    # smoothing: 0.1
  select: mit_bih_task.MITBIHTask

trainer:
  resume:  # 添加断点恢复配置
      enabled: false
      checkpoint: /home/lingyus/code/PRL/experiments/2025-01-10/14-27-21/checkpoint/checkpoint_step_8488.pt
  fp16: true
  # total_steps: 31980
  total_epochs: 1000
  update_interval: 1
  # save_interval: 1066
  # eval_interval: 1066
  log_interval: 20
  eval_metric:
    select: accuracy
    mode: max
  metrics: [accuracy, precision_macro, f1_macro, recall_macro]
    

distributed:
  backend: nccl
  world_size: 1
  distributed_no_spawn: false