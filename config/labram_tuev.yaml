common:
  seed: 0
  verbose: true
  exp_dir: experiments

dataset:
  batch_size: 64
  dataset: tuev_dataset.TUEVDataset
  num_workers: 4
  root_path:
    train: '/home/lingyus/data/tuh_eeg_events/v2.0.1/edf/train/'
    val:
    test: '/home/lingyus/data/tuh_eeg_events/v2.0.1/edf/eval/'
  io_path:
    train: "/mnt/ssd/lingyus/tuh_eeg_events/v2.0.1/edf/processed_train"
    val:
    test: "/mnt/ssd/lingyus/tuh_eeg_events/v2.0.1/edf/processed_eval"
  split: 
    select: HoldOutCross
    init_params:
      split_path: /mnt/ssd/lingyus/tuh_eeg_events/v2.0.1/edf/split
      group_by: subject_id
      val_size: 0.2
      random_state: 4523
      shuffle: true
  # before_segment_transform:
  #   eeg:
  #     PickChannels:
  #       channels: ['FP1', 'FP2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2', 'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'A1', 'A2', 'FZ', 'CZ', 'PZ', 'T1', 'T2']
  #     OrderChannels:
  #       order: ['FP1', 'FP2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2', 'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'A1', 'A2', 'FZ', 'CZ', 'PZ', 'T1', 'T2']
  #     Filter:
  #       l_freq: 0.1
  #       h_freq: 75
  #     NotchFilter:
  #       freqs: [50.0]
  #     Resample:
  #       desired_: 200.0
  # online_signal_transform:
  #   eeg:
  #     ToIndexChannels:
  #       channels: ['FP1', 'FP2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2', 'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'A1', 'A2', 'FZ', 'CZ', 'PZ', 'T1', 'T2']
  


lr_scheduler:
  select: CosineLRScheduler
  period_epochs: 50
  min_lr: 1e-6
  warmup_start_lr: 0
  warmup_epochs: 5

model:
  select: labram.labram_base_patch200_200
  trainable: true
  finetune: /home/lingyus/code/PRL/models/labram/checkpoints/labram-base.pth
  nb_classes: 6
  drop: 0.0
  drop_path: 0.1
  attn_drop_rate: 0.0
  drop_block_rate: null
  use_mean_pooling: true
  init_scale: 0.001
  rel_pos_bias: false
  abs_pos_emb: true
  layer_scale_init_value: 0.1
  qkv_bias: false

optimizer:
  lr: 5e-4
  select: AdamW
  weight_decay: 0.05             # 权重衰减 (L2正则化)
  layer_decay: 0.65                # 层级学习率衰减

task:
  loss:
    select: LabelSmoothingCrossEntropy
    smoothing: 0.1
  select: tuev_task.TUEVTask

trainer:
  resume:  # 添加断点恢复配置
      enabled: false
      checkpoint: /home/lingyus/code/PRL/experiments/2025-01-10/14-27-21/checkpoint/checkpoint_step_8488.pt
  fp16: true
  # total_steps: 31980
  total_epochs: 50
  update_interval: 8
  # save_interval: 1066
  # eval_interval: 1066
  log_interval: 20
  eval_metric:
    select: balanced_accuracy
    mode: max
  metrics: [balanced_accuracy, accuracy, f1_weighted, cohen_kappa]
    

distributed:
  backend: nccl
  world_size: 1
  distributed_no_spawn: false